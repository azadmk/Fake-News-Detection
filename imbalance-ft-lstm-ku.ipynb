{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9972841,"sourceType":"datasetVersion","datasetId":6135721},{"sourceId":9975800,"sourceType":"datasetVersion","datasetId":6137934}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import fasttext\nimport pandas as pd\nimport numpy as np\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout, Bidirectional\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport string\nfrom collections import Counter","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-17T16:59:04.822173Z","iopub.execute_input":"2025-02-17T16:59:04.822621Z","iopub.status.idle":"2025-02-17T16:59:23.273544Z","shell.execute_reply.started":"2025-02-17T16:59:04.822572Z","shell.execute_reply":"2025-02-17T16:59:23.272208Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"nltk.download('stopwords')\nnltk.download('wordnet')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T16:59:23.275037Z","iopub.execute_input":"2025-02-17T16:59:23.275813Z","iopub.status.idle":"2025-02-17T16:59:23.432094Z","shell.execute_reply.started":"2025-02-17T16:59:23.275765Z","shell.execute_reply":"2025-02-17T16:59:23.430896Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# Load dataset\ndsk = pd.read_excel('/kaggle/input/kurdishkdfnd/KDFND_Anlyzed_Cleaned_Filtered_Labeld.xlsx')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T16:59:23.434199Z","iopub.execute_input":"2025-02-17T16:59:23.434621Z","iopub.status.idle":"2025-02-17T16:59:40.938002Z","shell.execute_reply.started":"2025-02-17T16:59:23.434588Z","shell.execute_reply":"2025-02-17T16:59:40.936772Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"dsk = dsk.dropna(subset=['Text'])\ndsk[\"Article\"] = dsk[\"Text\"]\ndsk['label'] = dsk['label'].map({'Real': 0, 'Fake': 1})  # Convert labels to 0 and 1\ndsk = dsk[['Article', 'label']].dropna()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T16:59:40.939172Z","iopub.execute_input":"2025-02-17T16:59:40.939909Z","iopub.status.idle":"2025-02-17T16:59:41.055332Z","shell.execute_reply.started":"2025-02-17T16:59:40.939870Z","shell.execute_reply":"2025-02-17T16:59:41.054098Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from sklearn.utils import resample\n# Assuming 'dsk' is your DataFrame and you have a binary label column called 'label'\n# Split the dataset into majority and minority classes\nmajority_class = dsk[dsk['label'] == 0]\nminority_class = dsk[dsk['label'] == 1]\n\n# Perform oversampling on the minority class # Sample with replacement  # Match majority size\n###minority_oversampled = resample(minority_class,replace=True, n_samples=len(majority_class), random_state=42)  # For reproducibility\n# Perform undersampling on the minority class\nmajority_undersampled = resample(majority_class,replace=True, n_samples=len(minority_class), random_state=42)  # For reproducibility\n\n# Combine majority class with the oversampled minority class\n###dskb = pd.concat([majority_class, minority_oversampled])\n# Combine majority class with the undersampled minority class\n#dskb = pd.concat([minority_class, majority_undersampled])\n\n# Shuffle the dataset\n#dskb = dskb.sample(frac=1, random_state=42).reset_index(drop=True)\n#print(\"Balanced class distribution:\")\n#print(dskb['label'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T16:59:41.056368Z","iopub.execute_input":"2025-02-17T16:59:41.056716Z","iopub.status.idle":"2025-02-17T16:59:41.079349Z","shell.execute_reply.started":"2025-02-17T16:59:41.056677Z","shell.execute_reply":"2025-02-17T16:59:41.077937Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Tokenize and count word frequencies\nall_words = ' '.join(dsk).split()\nword_freq = Counter(all_words)\n\n# Identify potential stopwords (e.g., words appearing very frequently)\npotential_stopwords = [word for word, freq in word_freq.items() if freq > 1]\n\n# Example stopwords list (refined manually)\nkurdish_stopwords = [\n     \"ئێمە\",\"ئێوە\",\"ئەم\",\"ئەو\"\n     ,\"ئەوان\",\"ئەوەی\",\"بۆ\",\"بێ\",\"بێجگە\",\"بە\",\"بەبێ\",\"بەدەم\",\"بەردەم\",\"بەرلە\",\"بەرەوی\",\"بەرەوە\",\"بەلای\",\"بەپێی\",\"تۆ\",\"تێ\",\"جگە\",\"دوای\",\"دوو\",\"دە\"\n     ,\"دەکات\",\"دەگەڵ\",\"سەر\",\"لێ\",\"لە\",\"لەبابەت\",\"لەباتی\",\"لەبارەی\",\"لەبرێتی\",\"لەبن\",\"لەبەر\",\"لەبەینی\",\"لەدەم\",\"لەرێ\",\"لەرێگا\",\"لەرەوی\",\"لەسەر\",\"لەلایەن\"\n     ,\"لەناو\",\"لەنێو\",\"لەو\",\"لەپێناوی\",\"لەژێر\",\"لەگەڵ\",\"من\",\"ناو\",\"نێوان\",\"هەر\",\"هەروەها\",\"و\",\"وەک\",\"پاش\",\"پێ\",\"پێش\",\"چەند\",\"کرد\",\"کە\",\"ی\"\n\n] + potential_stopwords\n\nkupunctuation = {'!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?',\n                 '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~'}\n\n# Convert set to list before concatenation\nku_stopwords = kurdish_stopwords + list(kupunctuation)\n\ndef rremove_stopwords(text, stop_words):\n    words = text.split()\n    filtered_words = [word for word in words if word.lower() not in stop_words]\n    return ' '.join(filtered_words)\n    \n# Apply the function to each article\ndsk['Article'] = dsk['Article'].apply(lambda text: rremove_stopwords(text, ku_stopwords))\ndsk","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T17:01:15.070038Z","iopub.execute_input":"2025-02-17T17:01:15.070526Z","iopub.status.idle":"2025-02-17T17:01:19.140498Z","shell.execute_reply.started":"2025-02-17T17:01:15.070490Z","shell.execute_reply":"2025-02-17T17:01:19.139403Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                                  Article  label\n0       ئەرشیف هاونیشتمانی بەیەکەوە پاسپۆرتەکانی عێراق...      1\n1                            هێشتا هەرجوانە دڵێکی بۆدانێن      1\n2       نەخۆشخانەی ڕانییە قەرەبالغیەکی یەکجار زۆر هەی،...      1\n3                                             ئێستا ڕانیە      1\n4       هاوڕی باشەکان گرنگی یەکتر دەدەن هاوڕێ نزیکەکان...      1\n...                                                   ...    ...\n100957  کەرکووک؛ پیاوێکی 52 ساڵ گوشاری هاوژینەکەیدا ما...      0\n100958              تەقینەوەیەک ناوچەی سەوزی بەغدا ڕوویدا      0\n100959  باسیان لەچی کرد؟ زانیاری ورد بخوێنەوە پاپاوە س...      0\n100960        ئێران گیانلەدەستدانی خۆپیشاندەرێکی ڕاگەیاند      0\n100961              فڕۆکەکانی تورکیا شنگالیان بۆردومانکرد      0\n\n[100962 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Article</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ئەرشیف هاونیشتمانی بەیەکەوە پاسپۆرتەکانی عێراق...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>هێشتا هەرجوانە دڵێکی بۆدانێن</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>نەخۆشخانەی ڕانییە قەرەبالغیەکی یەکجار زۆر هەی،...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ئێستا ڕانیە</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>هاوڕی باشەکان گرنگی یەکتر دەدەن هاوڕێ نزیکەکان...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>100957</th>\n      <td>کەرکووک؛ پیاوێکی 52 ساڵ گوشاری هاوژینەکەیدا ما...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>100958</th>\n      <td>تەقینەوەیەک ناوچەی سەوزی بەغدا ڕوویدا</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>100959</th>\n      <td>باسیان لەچی کرد؟ زانیاری ورد بخوێنەوە پاپاوە س...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>100960</th>\n      <td>ئێران گیانلەدەستدانی خۆپیشاندەرێکی ڕاگەیاند</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>100961</th>\n      <td>فڕۆکەکانی تورکیا شنگالیان بۆردومانکرد</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>100962 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"def wordpre(text):\n    if not isinstance(text, str):\n        return \"\"  # Return empty string for non-string inputs\n    # Remove URLs, special characters, and numbers\n    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n    text = re.sub(r'\\@\\w+|\\#', '', text)\n    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n    text = text.translate(str.maketrans('', '', string.punctuation))\n    text = re.sub(r'\\d+', '', text)      # Remove numbers\n    \n    # Remove extra spaces\n    text = text.strip()\n   \n    return text\n\n##  Applying the wordpre method to the dataset\ndsk['Article']=dsk['Article'].apply(wordpre)\ndsk","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T17:01:20.401716Z","iopub.execute_input":"2025-02-17T17:01:20.402215Z","iopub.status.idle":"2025-02-17T17:01:25.016998Z","shell.execute_reply.started":"2025-02-17T17:01:20.402163Z","shell.execute_reply":"2025-02-17T17:01:25.015285Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                                  Article  label\n0       ئەرشیف هاونیشتمانی بەیەکەوە پاسپۆرتەکانی عێراق...      1\n1                            هێشتا هەرجوانە دڵێکی بۆدانێن      1\n2       نەخۆشخانەی ڕانییە قەرەبالغیەکی یەکجار زۆر هەیب...      1\n3                                             ئێستا ڕانیە      1\n4       هاوڕی باشەکان گرنگی یەکتر دەدەن هاوڕێ نزیکەکان...      1\n...                                                   ...    ...\n100957  کەرکووک پیاوێکی  ساڵ گوشاری هاوژینەکەیدا ماڵ د...      0\n100958              تەقینەوەیەک ناوچەی سەوزی بەغدا ڕوویدا      0\n100959  باسیان لەچی کرد زانیاری ورد بخوێنەوە پاپاوە سە...      0\n100960        ئێران گیانلەدەستدانی خۆپیشاندەرێکی ڕاگەیاند      0\n100961              فڕۆکەکانی تورکیا شنگالیان بۆردومانکرد      0\n\n[100962 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Article</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ئەرشیف هاونیشتمانی بەیەکەوە پاسپۆرتەکانی عێراق...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>هێشتا هەرجوانە دڵێکی بۆدانێن</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>نەخۆشخانەی ڕانییە قەرەبالغیەکی یەکجار زۆر هەیب...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ئێستا ڕانیە</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>هاوڕی باشەکان گرنگی یەکتر دەدەن هاوڕێ نزیکەکان...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>100957</th>\n      <td>کەرکووک پیاوێکی  ساڵ گوشاری هاوژینەکەیدا ماڵ د...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>100958</th>\n      <td>تەقینەوەیەک ناوچەی سەوزی بەغدا ڕوویدا</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>100959</th>\n      <td>باسیان لەچی کرد زانیاری ورد بخوێنەوە پاپاوە سە...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>100960</th>\n      <td>ئێران گیانلەدەستدانی خۆپیشاندەرێکی ڕاگەیاند</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>100961</th>\n      <td>فڕۆکەکانی تورکیا شنگالیان بۆردومانکرد</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>100962 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"dsk['label1'] = \"__label__\" + dsk['label'].astype(str)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T17:01:25.018995Z","iopub.execute_input":"2025-02-17T17:01:25.019470Z","iopub.status.idle":"2025-02-17T17:01:25.089530Z","shell.execute_reply.started":"2025-02-17T17:01:25.019431Z","shell.execute_reply":"2025-02-17T17:01:25.088176Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"dsk['label_description'] = dsk['label1'].astype(str) + \" \" + dsk['Article'].astype(str)\ndsk","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T17:01:25.982550Z","iopub.execute_input":"2025-02-17T17:01:25.983060Z","iopub.status.idle":"2025-02-17T17:01:26.063504Z","shell.execute_reply.started":"2025-02-17T17:01:25.983016Z","shell.execute_reply":"2025-02-17T17:01:26.062425Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                                  Article  label      label1  \\\n0       ئەرشیف هاونیشتمانی بەیەکەوە پاسپۆرتەکانی عێراق...      1  __label__1   \n1                            هێشتا هەرجوانە دڵێکی بۆدانێن      1  __label__1   \n2       نەخۆشخانەی ڕانییە قەرەبالغیەکی یەکجار زۆر هەیب...      1  __label__1   \n3                                             ئێستا ڕانیە      1  __label__1   \n4       هاوڕی باشەکان گرنگی یەکتر دەدەن هاوڕێ نزیکەکان...      1  __label__1   \n...                                                   ...    ...         ...   \n100957  کەرکووک پیاوێکی  ساڵ گوشاری هاوژینەکەیدا ماڵ د...      0  __label__0   \n100958              تەقینەوەیەک ناوچەی سەوزی بەغدا ڕوویدا      0  __label__0   \n100959  باسیان لەچی کرد زانیاری ورد بخوێنەوە پاپاوە سە...      0  __label__0   \n100960        ئێران گیانلەدەستدانی خۆپیشاندەرێکی ڕاگەیاند      0  __label__0   \n100961              فڕۆکەکانی تورکیا شنگالیان بۆردومانکرد      0  __label__0   \n\n                                        label_description  \n0       __label__1 ئەرشیف هاونیشتمانی بەیەکەوە پاسپۆرت...  \n1                 __label__1 هێشتا هەرجوانە دڵێکی بۆدانێن  \n2       __label__1 نەخۆشخانەی ڕانییە قەرەبالغیەکی یەکج...  \n3                                  __label__1 ئێستا ڕانیە  \n4       __label__1 هاوڕی باشەکان گرنگی یەکتر دەدەن هاو...  \n...                                                   ...  \n100957  __label__0 کەرکووک پیاوێکی  ساڵ گوشاری هاوژینە...  \n100958   __label__0 تەقینەوەیەک ناوچەی سەوزی بەغدا ڕوویدا  \n100959  __label__0 باسیان لەچی کرد زانیاری ورد بخوێنەو...  \n100960  __label__0 ئێران گیانلەدەستدانی خۆپیشاندەرێکی ...  \n100961   __label__0 فڕۆکەکانی تورکیا شنگالیان بۆردومانکرد  \n\n[100962 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Article</th>\n      <th>label</th>\n      <th>label1</th>\n      <th>label_description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ئەرشیف هاونیشتمانی بەیەکەوە پاسپۆرتەکانی عێراق...</td>\n      <td>1</td>\n      <td>__label__1</td>\n      <td>__label__1 ئەرشیف هاونیشتمانی بەیەکەوە پاسپۆرت...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>هێشتا هەرجوانە دڵێکی بۆدانێن</td>\n      <td>1</td>\n      <td>__label__1</td>\n      <td>__label__1 هێشتا هەرجوانە دڵێکی بۆدانێن</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>نەخۆشخانەی ڕانییە قەرەبالغیەکی یەکجار زۆر هەیب...</td>\n      <td>1</td>\n      <td>__label__1</td>\n      <td>__label__1 نەخۆشخانەی ڕانییە قەرەبالغیەکی یەکج...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ئێستا ڕانیە</td>\n      <td>1</td>\n      <td>__label__1</td>\n      <td>__label__1 ئێستا ڕانیە</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>هاوڕی باشەکان گرنگی یەکتر دەدەن هاوڕێ نزیکەکان...</td>\n      <td>1</td>\n      <td>__label__1</td>\n      <td>__label__1 هاوڕی باشەکان گرنگی یەکتر دەدەن هاو...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>100957</th>\n      <td>کەرکووک پیاوێکی  ساڵ گوشاری هاوژینەکەیدا ماڵ د...</td>\n      <td>0</td>\n      <td>__label__0</td>\n      <td>__label__0 کەرکووک پیاوێکی  ساڵ گوشاری هاوژینە...</td>\n    </tr>\n    <tr>\n      <th>100958</th>\n      <td>تەقینەوەیەک ناوچەی سەوزی بەغدا ڕوویدا</td>\n      <td>0</td>\n      <td>__label__0</td>\n      <td>__label__0 تەقینەوەیەک ناوچەی سەوزی بەغدا ڕوویدا</td>\n    </tr>\n    <tr>\n      <th>100959</th>\n      <td>باسیان لەچی کرد زانیاری ورد بخوێنەوە پاپاوە سە...</td>\n      <td>0</td>\n      <td>__label__0</td>\n      <td>__label__0 باسیان لەچی کرد زانیاری ورد بخوێنەو...</td>\n    </tr>\n    <tr>\n      <th>100960</th>\n      <td>ئێران گیانلەدەستدانی خۆپیشاندەرێکی ڕاگەیاند</td>\n      <td>0</td>\n      <td>__label__0</td>\n      <td>__label__0 ئێران گیانلەدەستدانی خۆپیشاندەرێکی ...</td>\n    </tr>\n    <tr>\n      <th>100961</th>\n      <td>فڕۆکەکانی تورکیا شنگالیان بۆردومانکرد</td>\n      <td>0</td>\n      <td>__label__0</td>\n      <td>__label__0 فڕۆکەکانی تورکیا شنگالیان بۆردومانکرد</td>\n    </tr>\n  </tbody>\n</table>\n<p>100962 rows × 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"train, test = train_test_split(dsk, test_size = 0.2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T17:01:31.270766Z","iopub.execute_input":"2025-02-17T17:01:31.271200Z","iopub.status.idle":"2025-02-17T17:01:31.316510Z","shell.execute_reply.started":"2025-02-17T17:01:31.271162Z","shell.execute_reply":"2025-02-17T17:01:31.315096Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"train.to_csv(\"fake_news_train.txt\", columns = ['label_description'], index=False, sep=' ', header=False,\n    quoting=3, escapechar=' ', mode='w')\ntest.to_csv(\"fake_news_test.txt\", columns = ['label_description'], index=False, sep=' ', header=False,\n    quoting=3, escapechar=' ', mode='w')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T17:01:32.937409Z","iopub.execute_input":"2025-02-17T17:01:32.937791Z","iopub.status.idle":"2025-02-17T17:01:33.643322Z","shell.execute_reply.started":"2025-02-17T17:01:32.937761Z","shell.execute_reply":"2025-02-17T17:01:33.641887Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Train FastText Model\nfasttext_model = fasttext.train_supervised(input=\"fake_news_train.txt\", lr=0.5, epoch=25, wordNgrams=2, dim=300)\ny_predic = fasttext_model.test(\"fake_news_test.txt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T17:01:35.148795Z","iopub.execute_input":"2025-02-17T17:01:35.149193Z","iopub.status.idle":"2025-02-17T17:02:24.642475Z","shell.execute_reply.started":"2025-02-17T17:01:35.149116Z","shell.execute_reply":"2025-02-17T17:02:24.641460Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"N = y_predic[0]\nP = y_predic[1]\nR = y_predic[2]\n\nprint(f\"No. of Test: {N:}\")\nprint(f\"Precision: {P:.6f}\")\nprint(f\"Recall: {R:.6f}\")\n\nprint(f\"F1-Score: {2*((P*R)/(P+R)):.6f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T17:02:24.643669Z","iopub.execute_input":"2025-02-17T17:02:24.643990Z","iopub.status.idle":"2025-02-17T17:02:24.652581Z","shell.execute_reply.started":"2025-02-17T17:02:24.643962Z","shell.execute_reply":"2025-02-17T17:02:24.651477Z"}},"outputs":[{"name":"stdout","text":"No. of Test: 20193\nPrecision: 0.802060\nRecall: 0.802060\nF1-Score: 0.802060\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Function to get FastText vector safely\ndef fasttext_vector(text):\n    if isinstance(text, str):  # Ensure text is a string\n        text = text.replace(\"\\n\", \" \").strip()  # Remove newlines\n        return fasttext_model.get_sentence_vector(text)\n    return np.zeros(300)  # Return zero vector for empty/non-string values\n\n# Apply FastText vectors to dataset\nX_fasttext = np.array([fasttext_vector(text) for text in dsk['Article']])\n# Function to get FastText vector\ny = np.array(dsk['label'])\n\n# Split dataset\nX_train, X_test, y_train, y_test = train_test_split(X_fasttext, y, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T17:02:24.654488Z","iopub.execute_input":"2025-02-17T17:02:24.654879Z","iopub.status.idle":"2025-02-17T17:02:29.689468Z","shell.execute_reply.started":"2025-02-17T17:02:24.654848Z","shell.execute_reply":"2025-02-17T17:02:29.688294Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Tokenization\nmax_words = 10000\nmax_len = 200\ntokenizer = Tokenizer(num_words=max_words)\ntokenizer.fit_on_texts(dsk['Article'])\nX_sequences = tokenizer.texts_to_sequences(dsk['Article'])\nX_padded = pad_sequences(X_sequences, maxlen=max_len)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T17:02:29.690646Z","iopub.execute_input":"2025-02-17T17:02:29.691016Z","iopub.status.idle":"2025-02-17T17:02:39.514042Z","shell.execute_reply.started":"2025-02-17T17:02:29.690975Z","shell.execute_reply":"2025-02-17T17:02:39.512956Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Embedding Matrix from FastText\nembedding_matrix = np.zeros((max_words, 300))\nfor word, i in tokenizer.word_index.items():\n    if i < max_words:\n        embedding_matrix[i] = fasttext_model.get_word_vector(word)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T17:02:39.515047Z","iopub.execute_input":"2025-02-17T17:02:39.515358Z","iopub.status.idle":"2025-02-17T17:02:39.662517Z","shell.execute_reply.started":"2025-02-17T17:02:39.515332Z","shell.execute_reply":"2025-02-17T17:02:39.661443Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# LSTM Model\nmodel = Sequential([\n    Embedding(input_dim=max_words, output_dim=300, weights=[embedding_matrix], input_length=max_len, trainable=True),\n    Bidirectional(LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)),\n    LSTM(32, dropout=0.2, recurrent_dropout=0.2),\n    Dense(16, activation='relu'),\n    Dropout(0.3),\n    Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T19:52:45.176936Z","iopub.execute_input":"2025-02-04T19:52:45.177239Z","iopub.status.idle":"2025-02-04T19:52:45.319622Z","shell.execute_reply.started":"2025-02-04T19:52:45.177215Z","shell.execute_reply":"2025-02-04T19:52:45.318375Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# Train Model\nmodel.fit(X_padded, y, epochs=5, batch_size=64, validation_split=0.2)\n\n# Evaluate\ny_pred = (model.predict(X_padded) > 0.5).astype(int)\naccuracy = accuracy_score(y, y_pred)\nprecision = precision_score(y, y_pred)\nrecall = recall_score(y, y_pred)\nf1 = f1_score(y, y_pred)\n\nprint(f\"Hybrid FastText-LSTM Model → Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T19:52:53.537296Z","iopub.execute_input":"2025-02-04T19:52:53.537760Z","iopub.status.idle":"2025-02-04T20:43:01.219254Z","shell.execute_reply.started":"2025-02-04T19:52:53.537722Z","shell.execute_reply":"2025-02-04T20:43:01.217991Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m564s\u001b[0m 442ms/step - accuracy: 0.8185 - loss: 0.4216 - val_accuracy: 0.7963 - val_loss: 0.4648\nEpoch 2/5\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m552s\u001b[0m 437ms/step - accuracy: 0.8633 - loss: 0.3301 - val_accuracy: 0.7674 - val_loss: 0.5823\nEpoch 3/5\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m549s\u001b[0m 435ms/step - accuracy: 0.8826 - loss: 0.2842 - val_accuracy: 0.7761 - val_loss: 0.5189\nEpoch 4/5\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m548s\u001b[0m 434ms/step - accuracy: 0.9023 - loss: 0.2376 - val_accuracy: 0.7787 - val_loss: 0.5993\nEpoch 5/5\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m543s\u001b[0m 430ms/step - accuracy: 0.9220 - loss: 0.1936 - val_accuracy: 0.7821 - val_loss: 0.6207\n\u001b[1m3156/3156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 79ms/step\nHybrid FastText-LSTM Model → Accuracy: 0.9092, Precision: 0.8810, Recall: 0.9450, F1-Score: 0.9119\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# LSTM Model\nmodel = Sequential([\n    Embedding(input_dim=max_words, output_dim=300, weights=[embedding_matrix], input_length=max_len, trainable=True),\n    LSTM(64, return_sequences=False, dropout=0.2, recurrent_dropout=0.2),\n    #LSTM(32, dropout=0.2, recurrent_dropout=0.2),\n    Dense(16, activation='relu'),\n    Dropout(0.3),\n    Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T17:02:59.746364Z","iopub.execute_input":"2025-02-17T17:02:59.746847Z","iopub.status.idle":"2025-02-17T17:02:59.885209Z","shell.execute_reply.started":"2025-02-17T17:02:59.746814Z","shell.execute_reply":"2025-02-17T17:02:59.883777Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Train Model\nmodel.fit(X_padded, y, epochs=5, batch_size=64, validation_split=0.2)\n\n# Evaluate\ny_pred = (model.predict(X_padded) > 0.5).astype(int)\naccuracy = accuracy_score(y, y_pred)\nprecision = precision_score(y, y_pred)\nrecall = recall_score(y, y_pred)\nf1 = f1_score(y, y_pred)\n\nprint(f\"Hybrid FastText-LSTM Model → Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T17:03:06.438385Z","iopub.execute_input":"2025-02-17T17:03:06.438828Z","iopub.status.idle":"2025-02-17T17:26:20.300478Z","shell.execute_reply.started":"2025-02-17T17:03:06.438796Z","shell.execute_reply":"2025-02-17T17:26:20.299120Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 204ms/step - accuracy: 0.8167 - loss: 0.4154 - val_accuracy: 0.7673 - val_loss: 0.5132\nEpoch 2/5\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 202ms/step - accuracy: 0.8670 - loss: 0.3202 - val_accuracy: 0.7961 - val_loss: 0.4622\nEpoch 3/5\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 200ms/step - accuracy: 0.8876 - loss: 0.2699 - val_accuracy: 0.7931 - val_loss: 0.5399\nEpoch 4/5\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 199ms/step - accuracy: 0.9055 - loss: 0.2249 - val_accuracy: 0.7280 - val_loss: 0.7752\nEpoch 5/5\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 201ms/step - accuracy: 0.9260 - loss: 0.1780 - val_accuracy: 0.7808 - val_loss: 0.7903\n\u001b[1m3156/3156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 38ms/step\nHybrid FastText-LSTM Model → Accuracy: 0.9142, Precision: 0.8868, Recall: 0.9485, F1-Score: 0.9166\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"model = Sequential([\n    #Embedding(input_dim=max_words, output_dim=300, weights=[embedding_matrix], input_length=max_len, trainable=True),\n    LSTM(128, return_sequences=False, input_shape=(X_train.shape[1], 1)),\n    Dropout(0.3),\n    #LSTM(64),\n    Dense(32, activation='relu'),\n    Dropout(0.2),\n    Dense(1, activation='sigmoid')\n])\n\n# Compile & Train\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T17:26:20.302185Z","iopub.execute_input":"2025-02-17T17:26:20.302609Z","iopub.status.idle":"2025-02-17T17:26:20.374927Z","shell.execute_reply.started":"2025-02-17T17:26:20.302568Z","shell.execute_reply":"2025-02-17T17:26:20.373679Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nmodel.fit(X_train, y_train, epochs=3, batch_size=64, validation_data=(X_test, y_test))\n\n\ny_pred = (model.predict(X_test) > 0.5).astype(int)\n\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\nprint(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\nprint(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\nprint(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T17:26:20.376546Z","iopub.execute_input":"2025-02-17T17:26:20.376894Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/3\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 329ms/step - accuracy: 0.8231 - loss: 0.5324 - val_accuracy: 0.9586 - val_loss: 0.1355\nEpoch 2/3\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 333ms/step - accuracy: 0.9602 - loss: 0.1444 - val_accuracy: 0.9583 - val_loss: 0.1368\nEpoch 3/3\n\u001b[1m 667/1263\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:53\u001b[0m 291ms/step - accuracy: 0.9577 - loss: 0.1462","output_type":"stream"}],"execution_count":null}]}